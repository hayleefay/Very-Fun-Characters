{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.sparse import csr_matrix\n",
    "from seqlearn.hmm import MultinomialHMM\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fully_annotated_files = os.listdir('fullyAnnotatedSequences')\n",
    "partially_annotated_files = os.listdir('partiallyAnnotatedSequences')\n",
    "feature_files = full_annotated_files + partially_annotated_files\n",
    "files = [filename.replace('sent','dat') for filename in feature_files]\n",
    "\n",
    "del files[50]\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "792"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Snigdha Chaturvedi's Features\n",
    "df = pd.read_csv('sequences_features/'+ files[0])\n",
    "df['filename'] = files[0].replace('.dat','.sent')\n",
    "i = 1\n",
    "df['sequence'] = i\n",
    "lengths = [len(df)]\n",
    "for file in files[1:]:\n",
    "    i += 1\n",
    "    small_df = pd.read_csv(\"sequences_features/\"+file)\n",
    "    lengths.append(len(small_df))\n",
    "    small_df['filename'] = file.replace('.dat','.sent')\n",
    "    small_df['sequence'] = i\n",
    "    df = df.append(small_df)\n",
    "df['unique_ID'] = df[\"filename\"].map(str) + df[\"1:sentId\"]  \n",
    "\n",
    "snigdha_feature_vars = ['29:posFramesFired',\n",
    " '30:negFramesFired',\n",
    " '31:otherFramesFired',\n",
    " '32:posFramewrtCharFired',\n",
    " '33:negFramewrtCharFired',\n",
    " '34:otherFrameswrtCharFired','unique_ID']\n",
    "snigdha_features = df[snigdha_feature_vars]\n",
    "len(snigdha_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping from sequence number to filename\n",
    "mapping = pd.read_csv('sequence_dictionary.txt', sep = ':::', header = None, engine = 'python')\n",
    "mapping.columns = ['sequence','filename']\n",
    "\n",
    "\n",
    "map_dict = {}\n",
    "for index,row in mapping.iterrows():\n",
    "    map_dict[row['sequence']] = row['filename']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "792"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Very Fun Team's features\n",
    "\n",
    "vft_features = pd.read_csv('fully_features.csv')\n",
    "sequences = vft_features['sequence'].tolist()\n",
    "seq_filenames = []\n",
    "for seq in sequences:    \n",
    "    seq_filenames.append(map_dict[seq])\n",
    "vft_features['filename'] = seq_filenames\n",
    "vft_features['unique_ID'] = vft_features['filename'].map(str) + vft_features['sid']\n",
    "\n",
    "\n",
    "vft_feature_vars = ['pos_acts_toeachother', 'neg_acts_toeachother',\n",
    "               'pos_acts_together', 'neg_acts_together',\n",
    "               'pos_char1_acts','neg_char1_acts', \n",
    "               'pos_char2_acts','neg_char2_acts',\n",
    "               'pos','neg']\n",
    "len(vft_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "792"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_features = vft_features.merge(snigdha_features, on=['unique_ID'])\n",
    "merged_features.to_csv(\"merged_features.csv\")\n",
    "len(merged_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "792"
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get target labels\n",
    "annotations = pd.read_csv('our_annotations.txt', sep = ':::', engine='python')\n",
    "sequences = annotations['sequence'].tolist()\n",
    "seq_filenames = []\n",
    "for seq in sequences:    \n",
    "    seq_filenames.append(map_dict[seq])\n",
    "annotations['filename'] = seq_filenames\n",
    "annotations['unique_ID'] = annotations['filename'].map(str) + annotations['sid']\n",
    "annotations = annotations[['unique_ID','manualLabel']]\n",
    "\n",
    "labelled_features = merged_features.merge(annotations, on=['unique_ID'])\n",
    "labelled_features.to_csv(\"labelled_features.csv\")\n",
    "len(labelled_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "603"
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_features = labelled_features.loc[labelled_features['manualLabel'].isin(['p','n'])]\n",
    "small_features.to_csv('filtered_labelled_features.csv')\n",
    "len(small_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feature_vars = snigdha_feature_vars + vft_feature_vars\n",
    "del all_feature_vars[6]\n",
    "\n",
    "def split_stuff(df):\n",
    "    y = np.asarray(df['manualLabel'])\n",
    "    y = y.astype('<U5')\n",
    "    lengths = np.asarray(df.groupby('sequence').count()['manualLabel'].tolist())    \n",
    "    features_df = df[all_feature_vars]\n",
    "    features_matrix = np.asmatrix(features_df)\n",
    "    features_sparse = csr_matrix(features_matrix)\n",
    "    X = features_sparse\n",
    "    return X,y,lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test:  (123, 22)\n",
      "train:  (480, 22)\n"
     ]
    }
   ],
   "source": [
    "# create training and testing sets\n",
    "# note that we split the data by sequence id so as to not break up sequences between train and test\n",
    "\n",
    "all_indices = list(range(1,101))\n",
    "test_indices = np.random.choice(all_indices, 20, replace=False)\n",
    "train_indices = [index for index in all_indices if index not in test_indices]\n",
    "\n",
    "test = small_features.loc[labelled_features['sequence'].isin(test_indices)]\n",
    "train = small_features.loc[labelled_features['sequence'].isin(train_indices)]\n",
    "print('test: ', test.shape)\n",
    "print('train: ', train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, lengths_train = split_stuff(train)\n",
    "X_test, y_test, lengths_test = split_stuff(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (480, 16)\n",
      "y  (480,)\n",
      "lengths  (80,)\n"
     ]
    }
   ],
   "source": [
    "print('X' ,X_train.shape)\n",
    "print('y ',y_train.shape)\n",
    "print('lengths ',lengths_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (123, 16)\n",
      "y  (123,)\n",
      "lengths  (20,)\n"
     ]
    }
   ],
   "source": [
    "print('X' ,X_test.shape)\n",
    "print('y ',y_test.shape)\n",
    "print('lengths ',lengths_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def namestr(obj, namespace):\n",
    "    return [name for name in namespace if namespace[name] is obj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sushmitavgopalan/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/sushmitavgopalan/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 19s, sys: 1.1 s, total: 2min 20s\n",
      "Wall time: 2min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "accuracies = []\n",
    "precision_0 = []\n",
    "precision_1 = []\n",
    "recall_0 = []\n",
    "recall_1 = []\n",
    "f1_0 = []\n",
    "f1_1 = []\n",
    "f1s = []\n",
    "\n",
    "for i in list(range(10000)):\n",
    "    \n",
    "    test_indices = np.random.choice(all_indices, 20, replace=False)\n",
    "    train_indices = [index for index in all_indices if index not in test_indices]\n",
    "\n",
    "    test = small_features.loc[labelled_features['sequence'].isin(test_indices)]\n",
    "    train = small_features.loc[labelled_features['sequence'].isin(train_indices)]\n",
    "\n",
    "    X_train, y_train, lengths_train = split_stuff(train)\n",
    "    X_test, y_test, lengths_test = split_stuff(test)\n",
    "\n",
    "    clf = MultinomialHMM()\n",
    "    #print(\"Training %s\" % clf)\n",
    "    clf.fit(X_train, y_train, lengths_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test, lengths_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(acc)\n",
    "    \n",
    "    p = precision_score(y_test, y_pred, average = None)\n",
    "    precision_0.append(p[0])\n",
    "    precision_1.append(p[1])\n",
    "    \n",
    "    f1 = f1_score(y_test, y_pred, average = None)\n",
    "    f1_0.append(f1[0])\n",
    "    f1_1.append(f1[1])\n",
    "    f1s.append(np.mean(f1))\n",
    "    \n",
    "    r = recall_score(y_test, y_pred, average = None)\n",
    "    recall_0.append(r[0])\n",
    "    recall_1.append(r[1])\n",
    "    #print(\"Accuracy: %.3f\" % (100 * accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracies\n",
      "Mean:  0.7823664506184783\n",
      "Std Dev:  0.07174002850740326\n",
      "precision_0\n",
      "Mean:  0.0\n",
      "Std Dev:  0.0\n",
      "precision_1\n",
      "Mean:  0.7823678234807778\n",
      "Std Dev:  0.0717421333785864\n",
      "recall_0\n",
      "Mean:  0.0\n",
      "Std Dev:  0.0\n",
      "recall_1\n",
      "Mean:  0.9999983050847459\n",
      "Std Dev:  0.00016948305063558216\n",
      "f1_0\n",
      "Mean:  0.0\n",
      "Std Dev:  0.0\n",
      "f1_1\n",
      "Mean:  0.8760505584645453\n",
      "Std Dev:  0.04593093091383474\n",
      "f1s\n",
      "Mean:  0.43802527923227264\n",
      "Std Dev:  0.02296546545691737\n"
     ]
    }
   ],
   "source": [
    "for metric in [accuracies,precision_0,precision_1,recall_0,recall_1,f1_0,f1_1,f1s]:\n",
    "    print(namestr(metric,globals())[1])\n",
    "    print('Mean: ', np.mean(metric))\n",
    "    print('Std Dev: ',np.std(metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "negs = [label for label in y if label == 'n']\n",
    "pos = [label for label in y if label == 'p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(negs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "472"
      ]
     },
     "execution_count": 590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "603"
      ]
     },
     "execution_count": 591,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "131 + 472"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21724709784411278"
      ]
     },
     "execution_count": 592,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "131/603"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "792-603"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
